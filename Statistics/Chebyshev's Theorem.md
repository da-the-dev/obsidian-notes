The probability that any [[random variable]] $X$ will assume a value within $k$ [[standard deviation|standard deviations]] of the [[mean]] is at least $1-\dfrac{1}{k^{2}}$. 
$$
P(\mu-k\sigma<X<\mu+k\sigma)\geq 1-\dfrac{1}{k^{2}}
$$
